<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Kapitel 5 - Scheduling."/>
    <title>5. CPU-Scheduling - Lernportal Betriebssysteme</title>
    <link rel="stylesheet" href="css/styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&family=Zilla+Slab:wght@700&display=swap" rel="stylesheet">
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$','$'], ['\\(','\\)']],
          displayMath: [['$$','$$'], ['\\[','\\]']],
          processEscapes: true
        }
      });
    </script>
</head>
<body>

<nav class="site-nav"></nav>

    <header>
        <div class="container">
            <h1>Kapitel 5: CPU-Scheduling</h1>
            <p>Die Kunst, zu entscheiden, welcher Prozess als Nächstes die CPU erhält.</p>
        </div>
    </header>

    <main class="container">
        <article class="content-section">

            <h2>Die Rolle und Ziele des Schedulers</h2>
            <p>Der <span class="key-term">Scheduler</span> (oder Dispatcher) ist die Komponente, die bestimmt, welcher Prozess als nächstes die CPU erhält. Entscheidungen fallen bei Zustandswechseln, z.B. wenn ein aktiver Prozess blockiert wird, ein Prozess seine Zeitscheibe aufgebraucht hat oder neue Prozesse in die Ready-Queue kommen.</p>
            <h3>Kriterien und Zielkonflikte</h3>
            <p>Ein Scheduler muss verschiedene, teils widersprüchliche Ziele ausbalancieren:</p>
            <ul>
                <li><strong>CPU-Auslastung:</strong> Die CPU soll möglichst dauerhaft beschäftigt sein.</li>
                <li><strong>Durchsatz:</strong> Maximierung der Anzahl abgeschlossener Prozesse pro Zeiteinheit.</li>
                <li><strong>Antwortzeit:</strong> Minimale Zeit von der Anforderung bis zur ersten sichtbaren Reaktion.</li>
                <li><strong>Fairness:</strong> Kein Prozess darf "verhungern", also unangemessen lange auf CPU-Zeit warten.</li>
                <li><strong>Stabilität:</strong> Vorhersehbares und kontrolliertes Verhalten auch bei hoher Systemlast.</li>
                <li><strong>Deadline-Einhaltung:</strong> In Echtzeitsystemen ist die Einhaltung von Fristen das oberste Kriterium.</li>
            </ul>
            <blockquote><strong>Overhead:</strong> Scheduling selbst verbraucht CPU-Zeit. Zu komplexe Algorithmen können kontraproduktiv sein, da der Aufwand für die Entscheidungsfindung die gewonnene Effizienz übersteigen kann.</blockquote>

            <h2>Leistungskennzahlen</h2>
            <ul>
                <li><strong>CPU-Auslastung</strong></li>
                <li><strong>Durchsatz (Throughput)</strong></li>
                <li><strong>Turnaround Time</strong> (Verweilzeit)</li>
                <li><strong>Wartezeit (Waiting Time)</strong></li>
                <li><strong>Antwortzeit (Response Time)</strong></li>
            </ul>

            <h2>Grundlegende Scheduling-Algorithmen</h2>

            <h3>First-Come, First-Served (FCFS)</h3>
            <ul>
                <li>Nicht-präemptiv: Ein Prozess gibt die CPU erst ab, wenn er blockiert oder fertig ist.</li>
                <li>Einfach, aber anfällig für den "Konvoi-Effekt", bei dem kurze Prozesse hinter einem langen Prozess warten müssen, was die durchschnittliche Wartezeit erhöht.</li>
            </ul>
            <div class="gantt">Beispiel: P1(24), P2(3), P3(3)<br>|---P1(24)---|--P2(3)--|--P3(3)--|<br>Ø Wartezeit = (0 + 24 + 27) / 3 = 17</div>

            <h3>Shortest-Job-First (SJF) / Shortest-Remaining-Time (SRT)</h3>
            <ul>
                <li>Wählt den Prozess mit der kürzesten geschätzten Ausführungszeit aus.</li>
                <li>Die präemptive Variante heißt <strong>Shortest-Remaining-Time (SRT)</strong> und wechselt den Prozess, wenn ein neuer Prozess mit einer kürzeren verbleibenden Laufzeit ankommt.</li>
                <li>Optimal bezüglich der minimalen durchschnittlichen Wartezeit, aber es besteht die Gefahr des Verhungerns für lange Prozesse.</li>
            </ul>
            <div class="gantt">Ablauf (SJF nicht-präemptiv, Start bei t=0): P1(6), P2(8), P3(7), P4(3)<br>|--P4(3)--|---P1(6)---|---P3(7)---|----P2(8)----|<br>Ø Wartezeit = (3 + 16 + 9 + 0) / 4 = 7</div>

            <h3>Prioritätsbasiertes Scheduling</h3>
            <ul>
                <li>Prozesse erhalten Prioritäten (statisch oder dynamisch). Der Prozess mit der höchsten Priorität wird ausgewählt.</li>
                <li>Meist präemptiv: Ein ankommender Prozess mit höherer Priorität verdrängt den laufenden Prozess.</li>
                <li>Problem: Verhungern von Prozessen mit niedriger Priorität. Lösung: "Aging", bei dem die Priorität wartender Prozesse mit der Zeit erhöht wird.</li>
                <li>Problem: <strong>Prioritätsinversion</strong>. Ein Prozess hoher Priorität wartet auf eine Ressource, die von einem Prozess niedriger Priorität gehalten wird, welcher wiederum von einem Prozess mittlerer Priorität verdrängt wird. Lösung: Priority Inheritance oder Priority Ceiling.</li>
            </ul>

            <h3>Round Robin (RR)</h3>
            <ul>
                <li>Jeder Prozess erhält eine feste Zeitscheibe (Quantum). Nach Ablauf des Quantums wird der Prozess verdrängt und ans Ende der Ready-Queue gestellt.</li>
                <li>Fair und sorgt für gute Antwortzeiten, aber ein zu kleines Quantum führt zu hohem Overhead durch häufige Kontextwechsel.</li>
            </ul>
            <div class="gantt">Beispiel (Quantum=4): P1(24), P2(3), P3(3)<br>|P1(4)|P2(3)|P3(3)|P1(4)|P1(4)|P1(4)|P1(4)|P1(4)|</div>

            <h3>Multilevel Queue Scheduling</h3>
            <p>Mehrere separate Ready-Queues für verschiedene Prozessklassen (z.B. interaktive Vordergrundprozesse, Batch-Hintergrundprozesse). Jede Queue kann einen eigenen Scheduling-Algorithmus verwenden.</p>
            <img src="images/placeholder.svg" class="illustration" alt="Diagramm: Ready Queues Hierarchie mit verschiedenen Prioritäten">

            <h3>Multilevel Feedback Queue (MLFQ)</h3>
            <p>Wie Multilevel Queue, aber Prozesse können zwischen den Queues wechseln. Ein Prozess, der viel CPU-Zeit verbraucht, kann in eine niedrigere Prioritäts-Queue mit längerem Quantum verschoben werden. Dies verhindert Verhungern und passt sich dem Prozessverhalten an.</p>

            <h3>Echtzeit-Scheduling</h3>
            <h4>Earliest Deadline First (EDF)</h4>
            <p>Dynamisches, präemptives Verfahren, das dem Prozess mit der frühesten Deadline die höchste Priorität gibt. Es ist optimal auf einem Prozessor, d.h., wenn eine Abfolge existiert, die alle Deadlines einhält, wird EDF sie finden. Unter Überlast kann es jedoch zu einem Dominoeffekt kommen, bei dem viele Tasks ihre Deadlines verpassen.</p>
            
            <h4>Rate Monotonic Scheduling (RMS)</h4>
            <p>Statisches, präemptives Verfahren für periodische Tasks. Die Priorität wird fest basierend auf der Periodendauer vergeben: je kürzer die Periode, desto höher die Priorität. RMS ist optimal, solange die CPU-Auslastung eine bestimmte Schranke nicht überschreitet: $\sum (C_i / P_i) \leq n(2^{1/n}-1)$, wobei C die Ausführungszeit und P die Periode ist. Für viele Prozesse konvergiert diese Schranke gegen $\ln(2) \approx 69.3\%$.</p>

            <h2>Scheduling in Mehrprozessorumgebungen</h2>
            <ul>
                <li><strong>Prozessoraffinität:</strong> Prozesse sollten möglichst auf derselben CPU bleiben, um die im lokalen Cache gehaltenen Daten weiter nutzen zu können und Cache-Invalidierungen zu minimieren.</li>
                <li><strong>Gang Scheduling:</strong> Gruppen von Threads, die eng zusammenarbeiten (eine "Gang"), werden gleichzeitig auf verschiedenen CPUs ausgeführt, um ineffiziente Wartezeiten zu vermeiden.</li>
            </ul>

            <h2>Scheduling in der Praxis</h2>
            <h3>Windows</h3>
            <ul>
                <li>Prioritätsbasiertes, präemptives Scheduling mit 32 Prioritätsstufen.</li>
                <li>Dynamische Prioritätsanpassung: Interaktive Threads (z.B. nach einer E/A-Operation) erhalten einen Prioritäts-Boost, während CPU-lastige Threads in der Priorität abgesenkt werden.</li>
                <li>Ein "Priority Boost" wird auch für lange wartende Threads (Anti-Starvation) durchgeführt.</li>
            </ul>
            <h3>Linux</h3>
            <ul>
                <li>Echtzeit-Klassen (FIFO, RR) haben Vorrang vor allen anderen.</li>
                <li>Der Standard-Scheduler für Nicht-Echtzeit-Prozesse (CFS - Completely Fair Scheduler) zielt darauf ab, jedem Prozess einen fairen Anteil an der CPU-Zeit zu geben, wobei I/O-lastige Threads bevorzugt werden, um die Antwortzeiten zu verbessern.</li>
            </ul>

            <h2>Zusammenfassung</h2>
            <ul>
                <li>Es gibt viele Scheduling-Algorithmen mit spezifischen Vor- und Nachteilen.</li>
                <li>Die Wahl des Algorithmus hängt stark vom Systemtyp ab: Batch, interaktiv oder Echtzeit.</li>
                <li>Die zentralen Herausforderungen sind die Trade-offs zwischen Durchsatz, Antwortzeiten, Fairness und dem eigenen Verwaltungsaufwand (Overhead).</li>
            </ul>

        </article>
    </main>

    <footer>
        <div class="container">
            <p>Erstellt zur Unterstützung der Prüfungsvorbereitung. Viel Erfolg bei der Klausur!</p>
        </div>
    </footer>

    <script src="js/main.js"></script>
</body>
</html>