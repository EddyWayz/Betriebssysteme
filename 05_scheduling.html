<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>5. CPU-Scheduling - Lernportal Betriebssysteme</title>
    <link rel="stylesheet" href="css/styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&family=Zilla+Slab:wght@700&display=swap" rel="stylesheet">
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$','$'], ['\\(','\\)']],
          displayMath: [['$$','$$'], ['\\[','\\]']],
          processEscapes: true
        }
      });
    </script>
    <style>
        .page-nav { background-color: #f8f9fa; padding: 10px 0; border-bottom: 1px solid var(--border-color); font-family: var(--header-font); }
        .page-nav a { color: var(--primary-color); text-decoration: none; font-weight: bold; }
        .page-nav a:hover { text-decoration: underline; }
        .content-section h3 { font-family: var(--title-font); font-size: 1.8rem; color: #444; margin-top: 40px; margin-bottom: 20px; }
        .content-section h4 { font-family: var(--title-font); font-size: 1.4rem; color: var(--primary-color); margin-top: 30px; }
        blockquote { border-left: 4px solid var(--primary-color); padding-left: 20px; margin: 20px 0; font-style: italic; background-color: var(--secondary-color); padding: 15px 20px; border-radius: 0 5px 5px 0; }
        .image-placeholder { background-color: #f0f0f0; border: 1px dashed #ccc; padding: 20px; text-align: center; margin: 20px auto; border-radius: 5px; color: #888; max-width: 80%; display: block; font-family: var(--header-font); }
        code, pre { font-family: Consolas, 'Courier New', monospace; background-color: #f5f5f5; border: 1px solid #ddd; border-radius: 4px; }
        code { padding: 2px 5px; }
        pre { padding: 15px; overflow-x: auto; white-space: pre-wrap; }
        .key-term { font-weight: bold; color: var(--primary-color); }
        table { width: 100%; margin-top: 20px; border-collapse: collapse; }
        th, td { border: 1px solid var(--border-color); padding: 12px; text-align: left; }
        th { background-color: var(--secondary-color); font-family: var(--header-font); }
        .gantt { border: 1px solid #ccc; padding: 10px; margin-top: 15px; font-family: monospace; white-space: pre; background: #fafafa; }
    </style>
</head>
<body>

    <nav class="site-nav">
        <div class="container">
            <a href="index.html">Zurück zur Übersicht</a>
            <a href="01_einfuehrung.html">1</a>
            <a href="02_grundlagen.html">2</a>
            <a href="03_prozesse.html">3</a>
            <a href="04_threads.html">4</a>
            <a href="05_scheduling.html" class="active">5</a>
            <a href="06_synchronisation.html">6</a>
            <a href="07_kommunikation.html">7</a>
            <a href="08_deadlocks.html">8</a>
            <a href="09_speicherverwaltung.html">9</a>
            <a href="10_dateisysteme.html">10</a>
        </div>
    </nav>

    <header>
        <div class="container">
            <h1>Kapitel 5: CPU-Scheduling</h1>
            <p>Die Kunst, zu entscheiden, welcher Prozess als Nächstes die CPU erhält.</p>
        </div>
    </header>

    <main class="container">
        <article class="content-section">
            <h2>Die Rolle und Ziele des Schedulers</h2>
            <p>Der <span class="key-term">Scheduler</span> (oder auch Dispatcher) ist die Komponente des Betriebssystems, die entscheidet, welcher der im Zustand <span class="key-term">"Bereit"</span> befindlichen Prozesse als nächstes die CPU zugeteilt bekommt. Er verwaltet dazu eine oder mehrere Warteschlangen, die sogenannten <span class="key-term">Ready Queues</span>.</p>
            <p>Ein Scheduling-Entscheidung muss in folgenden Situationen getroffen werden:</p>
            <ul>
                <li>Ein aktiver Prozess wechselt in den Zustand "blockiert" (z.B. durch eine E/A-Anforderung).</li>
                <li>Ein aktiver Prozess wird durch einen Timer-Interrupt verdrängt (präemptives Scheduling).</li>
                <li>Ein neuer Prozess wird erzeugt und in die Ready Queue gestellt.</li>
                <li>Ein blockierter Prozess beendet seine E/A-Operation und wird wieder bereit.</li>
            </ul>
            
            <h3>Kriterien und Zielkonflikte</h3>
            <p>Ein guter Scheduler versucht, mehrere, oft widersprüchliche Ziele auszubalancieren:</p>
            <ul>
                <li><strong>CPU-Auslastung:</strong> Die CPU soll so wenig wie möglich untätig sein.</li>
                <li><strong>Durchsatz:</strong> Die Anzahl der pro Zeiteinheit beendeten Prozesse soll maximiert werden.</li>
                <li><strong>Antwortzeit:</strong> Für interaktive Systeme soll die Zeit von der Benutzereingabe bis zur ersten Reaktion minimal sein.</li>
                <li><strong>Fairness:</strong> Jeder Prozess soll einen fairen Anteil an der CPU-Zeit erhalten und nicht <span class="key-term">verhungern</span> (Starvation).</li>
                <li><strong>Stabilität:</strong> Das System soll auch unter hoher Last (Overload) vorhersagbar und stabil bleiben.</li>
                <li><strong>Einhaltung von Terminen (Deadlines):</strong> In Echtzeitsystemen das wichtigste Kriterium.</li>
            </ul>
            <div class="image-placeholder">[Diagramm: Spinnennetz der Zielkonflikte]<br>Zeigt, wie die Optimierung eines Ziels (z.B. hoher Durchsatz durch lange Zeitscheiben) ein anderes (z.B. kurze Antwortzeit) negativ beeinflusst. Ein weiterer Konflikt besteht zwischen Fairness und der Einhaltung von Deadlines für hochpriorisierte Prozesse.</div>
            <blockquote><strong>Overhead des Schedulings:</strong> Jede Scheduling-Entscheidung und jeder Kontextwechsel verbrauchen selbst CPU-Zeit und sind reiner Overhead. Ein zu komplexer Algorithmus kann die Systemleistung daher sogar verschlechtern.</blockquote>

            <h2>Grundlegende Scheduling-Algorithmen</h2>

            <h4>1. First-Come, First-Served (FCFS)</h4>
            <ul>
                <li><strong>Prinzip:</strong> Prozesse werden in der Reihenfolge ihrer Ankunft in der Ready Queue abgearbeitet.</li>
                <li><strong>Art:</strong> Nicht-präemptiv. Ein Prozess gibt die CPU nur frei, wenn er fertig ist oder blockiert.</li>
                <li><strong>Vorteile:</strong> Sehr einfach zu implementieren und absolut fair, da kein Prozess verhungern kann.</li>
                <li><strong>Nachteile:</strong> Führt zu schlechten durchschnittlichen Warte- und Antwortzeiten, wenn ein kurzer Prozess hinter einem sehr langen Prozess ankommt (sog. <span class="key-term">Konvoi-Effekt</span>).</li>
            </ul>
            <div class="gantt">
            Beispiel: P1(24ms), P2(3ms), P3(3ms) kommen gleichzeitig an.<br>
            Ablauf: |---P1 (24ms)---|--P2(3ms)--|--P3(3ms)--|<br>
            Wartezeit P1=0, P2=24, P3=27. Durchschnitt: (0+24+27)/3 = 17ms.
            </div>

            <h4>2. Shortest-Job-First (SJF)</h4>
            <ul>
                <li><strong>Prinzip:</strong> Der Prozess mit der kürzesten geschätzten nächsten CPU-Bearbeitungszeit wird ausgewählt.</li>
                <li><strong>Art:</strong> Kann nicht-präemptiv oder präemptiv sein. Die präemptive Variante heißt <strong>Shortest-Remaining-Time (SRT)</strong>, bei der ein laufender Prozess verdrängt wird, sobald ein neuer Prozess mit einer noch kürzeren Restlaufzeit ankommt.</li>
                <li><strong>Vorteile:</strong> Ist beweisbar optimal in Bezug auf die minimale durchschnittliche Wartezeit.</li>
                <li><strong>Nachteile:</strong> Man muss die zukünftige CPU-Zeit kennen, was in der Praxis unmöglich ist (man kann sie nur schätzen). Es besteht die Gefahr, dass lange Prozesse <span class="key-term">verhungern</span>, wenn immer wieder kurze Prozesse nachkommen.</li>
            </ul>
            <div class="gantt">
            Beispiel: P1(24ms), P2(3ms), P3(3ms) kommen gleichzeitig an.<br>
            Ablauf: |--P2(3ms)--|--P3(3ms)--|---P1 (24ms)---|<br>
            Wartezeit P1=6, P2=0, P3=3. Durchschnitt: (6+0+3)/3 = 3ms. (Deutlich besser als FCFS)
            </div>

            <h4>3. Prioritätsbasiertes Scheduling</h4>
            <ul>
                <li><strong>Prinzip:</strong> Jeder Prozess erhält eine Priorität. Der Prozess mit der höchsten Priorität wird ausgeführt. Prioritäten können statisch (einmalig vergeben) oder dynamisch (zur Laufzeit angepasst) sein.</li>
                <li><strong>Art:</strong> Meist präemptiv: Ein neu ankommender Prozess mit höherer Priorität verdrängt den aktuell laufenden.</li>
                <li><strong>Vorteile:</strong> Erlaubt die gezielte Bevorzugung wichtiger Prozesse.</li>
                <li><strong>Problem 1: Starvation:</strong> Prozesse mit niedriger Priorität laufen möglicherweise nie. (Lösung: "Aging", d.h. die Priorität eines lange wartenden Prozesses wird langsam erhöht).</li>
                <li><strong>Problem 2: Prioritätsinversion:</strong> Ein hochpriorer Prozess P_A wartet auf eine Ressource, die von einem niederprioren Prozess P_C gehalten wird. Ein mittlerer Prozess P_B, der nichts mit der Ressource zu tun hat, verdrängt P_C, sodass dieser die Ressource nicht freigeben kann. Effektiv blockiert der unwichtigere Prozess P_B den hochprioren Prozess P_A.</li>
            </ul>

            <h4>4. Round Robin (RR)</h4>
            <ul>
                <li><strong>Prinzip:</strong> Eine FCFS-Queue wird mit Präemption kombiniert. Jeder Prozess erhält die CPU für eine feste, kleine Zeitscheibe, das <span class="key-term">Quantum</span> (z.B. 10-100 ms). Ist das Quantum abgelaufen, wird der Prozess unterbrochen, ans Ende der Ready Queue gestellt, und der nächste Prozess ist an der Reihe.</li>
                <li><strong>Art:</strong> Präemptiv.</li>
                <li><strong>Vorteile:</strong> Sehr fair, kein Verhungern, exzellente Antwortzeiten für interaktive Nutzer.</li>
                <li><strong>Nachteile:</strong> Die Leistung hängt stark von der Wahl des Quantums ab. Ist es zu groß, wird RR zu FCFS. Ist es zu klein, wird zu viel Zeit mit Kontextwechseln verschwendet.</li>
            </ul>

            <h2>Echtzeit-Scheduling</h2>
            <p>In Echtzeitsystemen ist nicht die durchschnittliche Leistung, sondern die <span class="key-term">garantierte Einhaltung von Deadlines</span> das oberste Ziel. Man unterscheidet:</p>
            <ul>
                <li><strong>Harte Echtzeit:</strong> Das Verpassen einer Deadline ist ein katastrophaler Systemfehler.</li>
                <li><strong>Weiche Echtzeit:</strong> Das Verpassen einer Deadline ist unerwünscht und mindert die Qualität, führt aber nicht zum Totalausfall.</li>
            </ul>
            <h4>Earliest Deadline First (EDF)</h4>
            <p>Ein präemptiver Algorithmus, der dynamisch Prioritäten vergibt: Der Prozess mit der frühesten (nächsten) Deadline hat die höchste Priorität.</p>
            <blockquote>EDF ist auf Einprozessorsystemen <strong>optimal</strong>: Wenn es irgendeine Möglichkeit gibt, alle Deadlines einzuhalten, wird EDF sie finden.</blockquote>
            <p>Nachteil: Unter Überlast (wenn nicht alle Deadlines haltbar sind) ist das Verhalten unvorhersehbar (Dominoeffekt).</p>
            
            <h4>Rate Monotonic Scheduling (RMS)</h4>
            <p>Ein Algorithmus für <span class="key-term">periodische</span> Tasks. Er vergibt statische Prioritäten: Je kürzer die Periode einer Task, desto höher ihre Priorität.</p>
            <p>RMS ist optimal, wenn eine bestimmte Bedingung erfüllt ist (hinreichend, nicht notwendig): Die Gesamtauslastung der CPU darf einen Schwellenwert nicht überschreiten. Für $n$ Prozesse mit Ausführungszeiten $C_i$ und Perioden $P_i$ gilt:</p>
            $$ \sum_{i=1}^{n} \frac{C_i}{P_i} \le n(2^{1/n}-1) $$
            <p>Dieser Grenzwert konvergiert für viele Prozesse ($n \to \infty$) gegen $\ln(2) \approx 69.3\%$.</p>

            <h2>Scheduling in Mehrprozessorumgebungen</h2>
            <p>Auf Systemen mit mehreren CPUs/Kernen muss der Scheduler nicht nur entscheiden, *wann* ein Prozess läuft, sondern auch *wo* (auf welchem Kern).</p>
            <ul>
                <li><strong>Prozessoraffinität:</strong> Es ist performanter, einen Prozess möglichst immer auf demselben Kern laufen zu lassen, damit dessen Daten im lokalen Cache des Kerns verbleiben. Ein ständiges "Hüpfen" zwischen Kernen ("job hopping") führt zu teuren Cache-Misses.</li>
                <li><strong>Gang Scheduling:</strong> Eine Gruppe von eng kooperierenden Threads (eine "Gang") wird als Einheit betrachtet und immer gleichzeitig auf verschiedenen Kernen ausgeführt. Dies verhindert, dass ein Thread der Gruppe blockiert, weil er auf einen anderen Thread wartet, der gerade nicht gescheduled ist.</li>
            </ul>

            <h2>Scheduling in der Praxis: Windows und Linux</h2>
            <h4>Windows</h4>
            <p>Windows verwendet ein prioritätsbasiertes, präemptives Scheduling für Threads.</p>
            <ul>
                <li>Es gibt 32 Prioritätsstufen. 1-15 sind für normale User-Threads, 16-31 sind Echtzeit-Prioritäten.</li>
                <li>Die Prioritäten im User-Bereich sind <span class="key-term">dynamisch</span>. Ein Thread, der eine E/A-Operation beendet (und oft interaktiv ist), erhält einen temporären Prioritäts-Boost. Ein Thread, der sein Zeitquantum voll ausnutzt (CPU-lastig), wird in der Priorität herabgestuft.</li>
                <li>Zur Bekämpfung von Starvation und Prioritätsinversion gibt es einen "Priority Boost": Lange wartende Threads werden kurzzeitig auf eine sehr hohe Priorität angehoben.</li>
            </ul>

            <h4>Linux</h4>
            <p>Auch Linux nutzt ein prioritätsbasiertes, präemptives Scheduling. Es unterscheidet verschiedene Scheduling-Klassen ("Policies"):</p>
            <ul>
                <li><strong>Echtzeit-Klassen (FIFO und RR):</strong> Für Tasks mit harten Echtzeitanforderungen. Diese werden immer vor allen anderen Tasks ausgeführt.</li>
                <li><strong>Nicht-Echtzeit-Klasse:</strong> Ein komplexer, fairer Algorithmus, der interaktive (I/O-lastige) Threads gegenüber CPU-lastigen Threads bevorzugt, um eine gute Systemreaktion zu gewährleisten.</li>
            </ul>
        </article>
    </main>

    <footer>
        <div class="container">
            <p>Erstellt zur Unterstützung der Prüfungsvorbereitung. Viel Erfolg bei der Klausur!</p>
        </div>
    </footer>

    <script src="js/main.js"></script>
</body>
</html>